{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# json vs tsv speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from qChronolyze import\n",
    "\n",
    "class row2DictCl:\n",
    "    def __init__(\n",
    "            self,surah_ayah='',position='',string='',meaning='',\n",
    "            # ayah_link='',\n",
    "            query=''\n",
    "        ):\n",
    "        self.surah_ayah = surah_ayah\n",
    "        self.position = position\n",
    "        self.string = string\n",
    "        self.meaning = meaning\n",
    "        # self.ayah_link = ayah_link\n",
    "        self.query = query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tblUp(tblCumul,tblAgg,instDct,stri,lnk\n",
    "            #   frm='',ptSp=''\n",
    "                ):\n",
    "        # for tbl in tbls:\n",
    "        #     # print(tbl)\n",
    "        #     tblAgg += tbl\n",
    "\n",
    "        # print(len(tblAgg))\n",
    "        \n",
    "        # print(f\"number of instances of {stri} in {lnk} before Adam filter: {len(tblAgg)}\")\n",
    "\n",
    "        if len(tblAgg) > 0:\n",
    "        # if len(tbls) > 0:\n",
    "            # print(f\"1st row of Table aggregate for {lnk} for {rt} is: {tblAgg[0].find_all('td')}\")\n",
    "            print(tblAgg[0].find_all('td')[1])\n",
    "            if 'adam' in tblAgg[0].find_all('td')[1].get_text().lower():\n",
    "            # if 'adam' in tbls[0].find_all('td')[1].get_text().lower():\n",
    "                if stri.lower() != 'adam' and stri != 'A^dam':\n",
    "                    # print(\"no results\")\n",
    "                    tblAgg = []\n",
    "                    # tbls = []\n",
    "\n",
    "        # print(f\"number of instances of {stri} in {lnk} after Adam filter: {len(tblAgg)}\")\n",
    "        # print(tblAgg)\n",
    "\n",
    "        tblCumul += tblAgg\n",
    "        # tblCumul += tbls\n",
    "\n",
    "        print(\"length of tblCumul: \", len(tblCumul))\n",
    "        # print(f\"total number of instances so far of {rt} without removing duplicates: {len(tblCumul)}\")\n",
    "\n",
    "        for rw in tblCumul:\n",
    "            row = [ fld.get_text() for fld in rw.find_all(\"td\") ]\n",
    "            # row = []\n",
    "            # for fld in rw:\n",
    "            #   row.append(fld.get_text())\n",
    "        \n",
    "            # print(row)\n",
    "            pos = row[0].split(' ')[0].strip('()')\n",
    "            # print(pos)\n",
    "            if pos not in instDct:\n",
    "                # print(posSplit)\n",
    "                posSplit = pos.split(':')\n",
    "                # print(posSplit)\n",
    "                # instLst.append({\n",
    "                instDct[pos] = row2DictCl(\n",
    "                    f'{posSplit[0]}:{posSplit[1]}', \n",
    "                    posSplit[2], \n",
    "                    row[0].split(' ')[1], \n",
    "                    row[1], \n",
    "                    # row[2], \n",
    "                )\n",
    "                # instDct[pos] = {\n",
    "                #         \"surah_ayah\": f'{posSplit[0]}:{posSplit[1]}',\n",
    "                #         #   \"position\": int(posSplit[2]), \n",
    "                #         \"position\": posSplit[2], \n",
    "                #         \"string\": row[0].split(' ')[1], \n",
    "                #         \"meaning\": row[1],\n",
    "                #         # \"form\": frm,\n",
    "                #         # \"p-o-s\": ptSp,\n",
    "                #         \"ayah_link\": row[2]\n",
    "                #     }\n",
    "                # # })\n",
    "        \n",
    "                # poss.add(pos)\n",
    "            else:\n",
    "                # if instDct[pos][\"form\"] == '' and frm != '':\n",
    "                #     instDct[pos][\"form\"] = frm\n",
    "                # if instDct[pos][\"p-o-s\"] == '' and ptSp != '':\n",
    "                #     instDct[pos][\"p-o-s\"] = ptSp\n",
    "                pass\n",
    "\n",
    "            # print(f\"number of unique instances upto {lnk}: {len(poss)} or {len(instLst)}\")\n",
    "            \n",
    "        print(len(tblCumul), len(instDct))\n",
    "        # print(tblAgg)\n",
    "\n",
    "        return tblCumul, instDct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webGet(stri,lnks,poSp,frm):\n",
    "    # import html2text\n",
    "    # import json\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "\n",
    "    def getTbl(grabhtmlPara):\n",
    "        soup = BeautifulSoup(\n",
    "            grabhtmlPara,\n",
    "            'lxml' \n",
    "        )\n",
    "\n",
    "        tblsRet = soup.find_all(\n",
    "            \"table\",\n",
    "            {\"class\":\"taf\"}\n",
    "        )\n",
    "\n",
    "        return tblsRet\n",
    "\n",
    "\n",
    "    # poss = set()\n",
    "    instDct={}\n",
    "    tblCumul = []\n",
    "    # tblAgg = []\n",
    "    print(f\"proper data not found for {stri}\")\n",
    "\n",
    "\n",
    "    for lnk in lnks:\n",
    "        print('\\ngetting for link: ', lnk, '\\n')\n",
    "        if lnk == f'https://corpus.quran.com/qurandictionary.jsp?q={stri}':\n",
    "            grabhtml = requests.get(lnk).text\n",
    "            # print(type(grabhtml))\n",
    "\n",
    "            import re\n",
    "\n",
    "            headTbls = re.findall('(<h4 class=\"dxe\">.*?(?=<h4))',grabhtml,re.DOTALL)\n",
    "\n",
    "            # print(len(headTbls))\n",
    "\n",
    "            for headTbl in headTbls:\n",
    "                tblAgg = []\n",
    "                soup = BeautifulSoup(\n",
    "                    headTbl,\n",
    "                    'lxml',\n",
    "                    # 'html.parser',\n",
    "                )\n",
    "                head4 = soup.find_all(\n",
    "                    \"h4\",\n",
    "                    {\"class\":\"dxe\"}\n",
    "                )[0]\n",
    "\n",
    "                # if len(tblsRet) > 0:\n",
    "                    # print(len(tblsRet) > 0)\n",
    "                    # print(len(tblsRet))\n",
    "                    # if len(tblsRet) == len(head4s):\n",
    "                    # print(len(tblsRet) == len(head4s))\n",
    "                # for i in range(len(head4s)):\n",
    "                    # print(head4s[i].text)\n",
    "\n",
    "                tblGrm = head4.text.split('-')[0]\n",
    "                tblForms = re.findall('\\(form (.*?)\\)', tblGrm)\n",
    "                if len(tblForms) == 0:\n",
    "                    tblForm = 'All'\n",
    "                else:\n",
    "                    # print(tempForms[0])\n",
    "                    tblForm = tblForms[0]\n",
    "                tblPoSps = re.findall(f'(^[^\\(\\)]*?(?=\\s*$|\\s*\\())', tblGrm)\n",
    "                if len(tblPoSps) == 0:\n",
    "                    tblPoSp = 'All'\n",
    "                else:\n",
    "                    # print(tempPtSps[0])\n",
    "                    tblPoSp = tblPoSps[0]\n",
    "\n",
    "                if tblForm == 'All':\n",
    "                    if tblPoSp != 'All':\n",
    "                        tblForm = 'I'\n",
    "                print(\n",
    "                    # grm, \n",
    "                    tblForm, \n",
    "                    tblPoSp\n",
    "                )\n",
    "\n",
    "                tbls = soup.find_all(\n",
    "                    \"table\",\n",
    "                    {\"class\":\"taf\"}\n",
    "                )\n",
    "\n",
    "                # tblAgg = [ tbl for tbl in tbls ]\n",
    "\n",
    "                # print(tblsRet)\n",
    "                for tbl in tbls:\n",
    "                    if tblPoSp == poSp and tblForm == frm:\n",
    "                        tblAgg += tbl\n",
    "                print(\"tblAgg length\", len(tblAgg))\n",
    "                tblCumul,instDct = tblUp(tblCumul,tblAgg,instDct,\n",
    "                                        #  tempForm,tempPtSp\n",
    "                                        stri,lnk\n",
    "                                            )\n",
    "\n",
    "\n",
    "        else:\n",
    "            pgs = []\n",
    "            tblAgg = []\n",
    "            grabhtml = requests.get(f\"{lnk}\").text\n",
    "            tbls = getTbl(grabhtml)\n",
    "            if 'Results' in grabhtml:\n",
    "                matches = re.findall(\">[\\n\\s]*Results[\\s\\n]*<b>\\d*</b>[\\s\\n]*to[\\s\\n]*<b>\\d*</b>[\\s\\n]*of[\\s\\n]*<b>(\\d*)</b>\", grabhtml, re.DOTALL)\n",
    "                # print('\\nmatches: ', matches)\n",
    "                if len(matches) > 0:\n",
    "                    pgFlt = int(matches[0])/50\n",
    "                    pgCount = int(pgFlt) + 1 if int(matches[0]) % 50 != 0 else int(pgFlt)\n",
    "                    # print(f\"page count in {lnk} is: {pgCount}\")\n",
    "                    # print(type(pgCount), pgCount)\n",
    "                    pgs = list(map(lambda x : f'&page={x}', list(range(2,pgCount+1))))\n",
    "\n",
    "                for pg in pgs:\n",
    "                    print(f'\\nin pg {pg}')\n",
    "                    grabhtml = requests.get(f\"{lnk}{pg}\").text\n",
    "                    tbls += getTbl(grabhtml)\n",
    "                    # print(f\"length of grabhtml is: {len(grabhtmlNew)}\")\n",
    "                    # grabhtml += grabhtmlNew\n",
    "                    # print(f\"length of grabhtml after adding is: {len(grabhtml)}\")\n",
    "                \n",
    "            for tbl in tbls:\n",
    "                tblAgg += tbl\n",
    "                \n",
    "            print(\"length of tblAgg: \", len(tblAgg))\n",
    "            \n",
    "            tblCumul,instDct = tblUp(tblCumul,tblAgg,instDct,stri,lnk)\n",
    "\n",
    "        # print(f\"\\nnumber of tables found in {lnk} for {rt} is: {len(tbls)}\")\n",
    "        # print(f\"{tbls}\\n\")\n",
    "        return instDct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = webGet(\"laA\",[\"https://corpus.quran.com/search.jsp?q=stem:laA\"],\"All\",\"All\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileWriteJson(filepath,instDct):\n",
    "    # list_header = ['surah_ayah', 'position', 'string', 'meaning', 'ayah_link'\n",
    "    #             #    'form', 'p-o-s', \n",
    "    #     ]\n",
    "    # print(f\"writing {stri} to '{filepath}'\")\n",
    "        # print(f\"writing {stri} to '{filepath}'\")\n",
    "    import json\n",
    "        # import csv\n",
    "        # writer = csv.DictWriter(f, delimiter='\\t', fieldnames=list_header)\n",
    "        # writer.writeheader()\n",
    "        # for datum in instLst:\n",
    "        # for k, datum in instDct.items():\n",
    "        # for datum in instDct.values():\n",
    "    \n",
    "    instLs = [row[:4] for datum in instDct.values() if (row := list(datum.__dict__.values())) ]\n",
    "            # writer.writerow({\n",
    "            #     # list_header[0] : datum['surah_ayah'],\n",
    "            #     # list_header[1] : datum['position'],\n",
    "            #     # list_header[2] : datum['string'],\n",
    "            #     # list_header[3] : datum['meaning'],\n",
    "            #     # list_header[4] : datum['ayah_link'],\n",
    "            #     list_header[0] : datum.surah_ayah,\n",
    "            #     list_header[1] : datum.position,\n",
    "            #     list_header[2] : datum.string,\n",
    "            #     list_header[3] : datum.meaning,\n",
    "            #     list_header[4] : datum.ayah_link,\n",
    "            #     # list_header[4] : datum['form'],\n",
    "            #     # list_header[5] : datum['p-o-s'],\n",
    "            # })\n",
    "    with open(f'{filepath}', 'w+') as f:\n",
    "        f.write(json.dumps(instLs))\n",
    "    \n",
    "    # return instDct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileWriteTsv(filepath,instDct):\n",
    "    list_header = ['surah_ayah', 'position', 'string', 'meaning', \n",
    "                #    'ayah_link'\n",
    "                #    'form', 'p-o-s', \n",
    "        ]\n",
    "    # print(f\"writing {stri} to '{filepath}'\")\n",
    "    with open(f'{filepath}', 'w+') as f:\n",
    "        # print(f\"writing {stri} to '{filepath}'\")\n",
    "        import csv\n",
    "        writer = csv.DictWriter(f, delimiter='\\t', fieldnames=list_header)\n",
    "        writer.writeheader()\n",
    "        # for datum in instLst:\n",
    "        # for k, datum in instDct.items():\n",
    "        for datum in instDct.values():\n",
    "            writer.writerow({\n",
    "                # list_header[0] : datum['surah_ayah'],\n",
    "                # list_header[1] : datum['position'],\n",
    "                # list_header[2] : datum['string'],\n",
    "                # list_header[3] : datum['meaning'],\n",
    "                # list_header[4] : datum['ayah_link'],\n",
    "                list_header[0] : datum.surah_ayah,\n",
    "                list_header[1] : datum.position,\n",
    "                list_header[2] : datum.string,\n",
    "                list_header[3] : datum.meaning,\n",
    "                # list_header[4] : datum.ayah_link,\n",
    "                # list_header[4] : datum['form'],\n",
    "                # list_header[5] : datum['p-o-s'],\n",
    "            })\n",
    "    \n",
    "    # return instDct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeBegin = time.time()\n",
    "fileWriteJson(\"test1.json\",data1)\n",
    "timeEnd = time.time()\n",
    "timeTakenJsonWrite = timeBegin-timeEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeBegin = time.time()\n",
    "fileWriteTsv(\"test1.tsv\",data1)\n",
    "timeEnd = time.time()\n",
    "timeTakenTsvWrite = timeBegin-timeEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for writing TSV is faster than json by: -69.59960800783985 %\n"
     ]
    }
   ],
   "source": [
    "print(\"for writing TSV is faster than json by:\", (timeTakenJsonWrite-timeTakenTsvWrite)/timeTakenJsonWrite*100, \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileReadJson(filepath):\n",
    "        list_header = ['surah_ayah', 'position', 'string', 'meaning', \n",
    "                    #    'ayah_link'\n",
    "                #    'form', 'p-o-s', \n",
    "        ]\n",
    "\n",
    "        row_width = len(list_header)\n",
    "\n",
    "        import json\n",
    "        # print(f\"file found for {stri}\")\n",
    "        instDct = {}\n",
    "        # try:\n",
    "        with open(filepath) as f:\n",
    "            # print(f\"loading {filepath}\")\n",
    "            instTbl = json.loads(f.read())\n",
    "        print(len(instTbl))\n",
    "            # instLst = [row for row in csv.DictReader(f, delimiter='\\t') ]\n",
    "        for row in instTbl:\n",
    "            surAyPos = f'{row[0]}:{row[1]}'\n",
    "            # print('for ', surAyPos)\n",
    "            # surAyPos = f'{row[\"surah_ayah\"]}:{row[\"position\"]}'\n",
    "            dicti = {\n",
    "                list_header[i]: row[i]\n",
    "                for i in range(row_width)\n",
    "            }\n",
    "            # instDct[surAyPos] = row\n",
    "            instDct[surAyPos] = row2DictCl(**dicti)\n",
    "            # print(instDct[surAyPos].__dict__)\n",
    "\n",
    "        print(f\"Successfully loaded data from '{filepath}: lenght {len(instDct)}'\")\n",
    "            # propDat = True\n",
    "        # except:\n",
    "        #     # propDat = False\n",
    "        #     instDct = {}\n",
    "        #     print(f\"couldn't load data from '{filepath}': lenght {len(instDct)}\")\n",
    "        \n",
    "        return instDct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileReadTsv(filepath):\n",
    "        import csv\n",
    "        # print(f\"file found for {stri}\")\n",
    "        instDct = {}\n",
    "        # try:\n",
    "        with open(filepath) as f:\n",
    "            print(f\"loading {filepath}\")\n",
    "            instTbl = csv.DictReader(f, delimiter='\\t')\n",
    "\n",
    "            # print(len(instTbl))\n",
    "            # instLst = [row for row in csv.DictReader(f, delimiter='\\t') ]\n",
    "            for row in instTbl:\n",
    "                surAyPos = f'{row[\"surah_ayah\"]}:{row[\"position\"]}'\n",
    "                # print('for ', surAyPos)\n",
    "                # surAyPos = f'{row[\"surah_ayah\"]}:{row[\"position\"]}'\n",
    "\n",
    "                # instDct[surAyPos] = row\n",
    "                instDct[surAyPos] = row2DictCl(**row)\n",
    "                # print(instDct[surAyPos].__dict__)\n",
    "\n",
    "            print(f\"Successfully loaded data from '{filepath}: lenght {len(instDct)}'\")\n",
    "            # propDat = True\n",
    "        # except:\n",
    "        #     # propDat = False\n",
    "        #     instDct = {}\n",
    "            # print(f\"couldn't load data from '{filepath}': lenght {len(instDct)}\")\n",
    "        \n",
    "        return instDct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1689\n",
      "Successfully loaded data from 'test1.json: lenght 1689'\n"
     ]
    }
   ],
   "source": [
    "timeBegin = time.time()\n",
    "data1 = fileReadJson(\"test1.json\")\n",
    "timeEnd = time.time()\n",
    "timeTakenJsonRead = timeBegin-timeEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test1.tsv\n",
      "Successfully loaded data from 'test1.tsv: lenght 1689'\n"
     ]
    }
   ],
   "source": [
    "timeBegin = time.time()\n",
    "data2 = fileReadTsv(\"test1.tsv\")\n",
    "timeEnd = time.time()\n",
    "timeTakenTsvRead = timeBegin-timeEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for reading TSV is faster than json by: -19.43990106514541 %\n"
     ]
    }
   ],
   "source": [
    "print(\"for reading TSV is faster than json by:\", (timeTakenJsonRead-timeTakenTsvRead)/timeTakenJsonRead*100, \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 lenghth == data2 lenght  True\n"
     ]
    }
   ],
   "source": [
    "lenData1 = len(data1)\n",
    "isEqualData = lenData1 == len(data2)\n",
    "print(\"data1 lenghth == data2 lenght \", isEqualData)\n",
    "\n",
    "if isEqualData:\n",
    "    # for i in range(lenData1):\n",
    "    data1Keys = list(data1.keys())\n",
    "    data1Values = list(data1.values())\n",
    "    data2Keys = list(data1.keys())\n",
    "    data2Values = list(data1.values())\n",
    "    for i in range(lenData1):\n",
    "        if data1Keys[i] != data2Keys[i]:\n",
    "            print(f\"for {i} data1 key is {data1Keys[i]} and data2 key is {data2Keys[i]}\")\n",
    "        else:\n",
    "            if data1Values[i].__dict__ != data2Values[i].__dict__:\n",
    "                print(f\"for {i} data1 value is {data1Values[i]} and data2 Value is {data2Values[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
